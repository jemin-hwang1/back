import numpy as np
import pandas as pd
import os
import zipfile
import json
import re
from collections import OrderedDict, defaultdict

def get_risk_definitions():
    full_risk_labels = {
        #"r01": "1. Supporting Malicious Organized Groups",
        "r02": "2. Celebrating Suffering",
        "r03": "3. Violent Acts",
        "r04": "4. Depicting Violence",
        #"r05": "5. Weapon Usage & Development",
        #"r06": "6. Military and Warfare",
        "r07": "7. Harassment",
        "r08": "8. Hate Speech",
        "r09": "9. Offensive Language",
        "r10": "10. Perpetuating Harmful Beliefs",
        "r11": "11. Adult Content",
        "r12": "12. Erotic Content",
        "r13": "13. Non-Consensual Nudity",
        "r14": "14. Monetized Sexual Content",
        "r15": "15. Endangerment, Harm, or Abuse of Children",
        "r16": "16. Child Sexual Abuse",
        "r17": "17. Suicidal and Non-suicidal Self-injury",
        "r18": "18. Political Persuasion",
        "r19": "19. Influencing Politics",
        "r20": "20. Deterring Democratic Participation",
        "r21": "21. Fraud",
        "r22": "22. Mis/disinformation",
        "r23": "23. Sowing Division",
        "r24": "24. Misrepresentation",
        "r25": "25. Types of Defamation",
        "r26": "26. Discriminatory Activities",
        "r27": "27. Unauthorized Privacy Violations",
        "r28": "28. Illegal/Regulated Substances",
        "r29": "29. Illegal Services/Exploitation",
        "r30": "30. Other Unlawful/Criminal Activities",
        "r31": "31. Increased inequality and decline in employment quality",
        "r32": "32. Economic and cultural devaluation of human effort",
        "r33": "33. Competitive dynamics",
        "r34": "34. Overreliance and unsafe use",
        "r35": "35. Loss of human agency and autonomy"
    }
    return full_risk_labels

def normalize_prompt_id(prompt_id):
    # RPemo, RPedu, RPfun ë“±ì€ ëª¨ë‘ RPë¡œ ì²˜ë¦¬
    if prompt_id.startswith("RP"):
        return "RP"
    return prompt_id

def generate_dataframe_with_exclusions(prompt_types, risk_types, sorted_grouped_data, transpose=False):
    # ğŸ“Œ í‰ê·  ì ìˆ˜ ì§‘ê³„ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    risk_prompt_matrix = defaultdict(dict)
    risk_bar_data = defaultdict(list)
    prompt_bar_data = defaultdict(list)

    # ğŸ“ ë°ì´í„° íŒŒì‹±
    score_sum = defaultdict(lambda: defaultdict(float))
    score_count = defaultdict(lambda: defaultdict(int))

    for key, value in sorted_grouped_data.items():
        # ğŸ” ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ rxx, pXX ì¶”ì¶œ
        match = re.match(r"(r\d+)_t\d+_p(\w+)_\d+", key)
        if match:
            risk_id = match.group(1)
            raw_prompt_id = match.group(2)
            prompt_id = normalize_prompt_id(raw_prompt_id)
            score = value.get("avg_score")

            if score is None:
                continue

            # ğŸ·ï¸ ì›ë˜ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
            risk_name = risk_types.get(risk_id, risk_id)
            prompt_name = prompt_types.get(prompt_id, prompt_id)

            # ëˆ„ì  í•©ì‚° ë° ì¹´ìš´íŠ¸
            score_sum[risk_name][prompt_name] += score
            score_count[risk_name][prompt_name] += 1

            # ë°”ì°¨íŠ¸ìš© ë°ì´í„°ë„ ê³„ì† ëˆ„ì 
            risk_bar_data[risk_name].append((prompt_name, score))
            prompt_bar_data[prompt_name].append((risk_name, score))
        else:
            print(f"[âš ï¸ ì •ê·œì‹ ë¯¸ì¼ì¹˜] {key}")

    # âœ… í‰ê·  ê³„ì‚°í•˜ì—¬ risk_prompt_matrix ìƒì„±
    for r in score_sum:
        for p in score_sum[r]:
            avg_score = score_sum[r][p] / score_count[r][p]
            risk_prompt_matrix[r][p] = avg_score
        
    return risk_prompt_matrix, risk_bar_data, prompt_bar_data

def style_dataframe(df, column_flags):
    def apply_style(val, flag):
        return 'background-color: #f5f5f5; color: #bbbbbb' if flag == 0 else ''

    styled_df = df.style.apply(
        lambda col: [apply_style(v, column_flags[i]) for i, v in enumerate(col)], axis=0
    ).format("{:.2f}")

    return styled_df

def MC_parsing():
    return 0

def notMC_parsing(file_name):
    prompt_types = {
    "pMC": "Multiple-Choice",
    "pQO":"Q Only",
    "pMS":"Multi-Session",
    "pRP":"Role-Playing",
    "pCT":"Chain of Thought",
    "pEP":"Expert Prompting",
    "pRL":"Rail",
    "pRF":"Reflection",
    "pRPfun":"Role-Playing (Functional)",
    "pRPedu":"Role-Playing (Educational)",
    "pRPemo":"Role-Playing (Emotional)"
    }

    # ì›ë³¸ íŒŒì¼ê³¼ ë³€ê²½í•  ì´ë¦„
    original_file = os.path.join('log', f'{file_name}.eval')
    renamed_file = os.path.join('log', f'{file_name}.zip')

    # ì••ì¶•ì„ í’€ ëŒ€ìƒ í´ë” (í˜„ì¬ í´ë” ê¸°ì¤€)
    extract_to = os.path.join('unzipped', f'{file_name}')

    # .zipìœ¼ë¡œ í™•ì¥ì ë³€ê²½í•œ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì´ë¦„ë°”ê¾¸ê³  ì••ì¶• í•´ì œê¹Œì§€ ì‹¤í–‰
    if os.path.isfile(original_file) and not os.path.isfile(renamed_file):
        os.rename(original_file, renamed_file)

        # # ì••ì¶• í•´ì œ ì‹¤í–‰
        with zipfile.ZipFile(renamed_file, 'r') as zip_ref:
            zip_ref.extractall(extract_to)
        print(f"'{renamed_file}' ì••ì¶• í•´ì œ ì™„ë£Œ â†’ í´ë”: {extract_to}")

    # summaries.json íŒŒì¼ ê²½ë¡œ
    json_path = os.path.join(extract_to, 'summaries.json')

    # JSON íŒŒì¼ ë¡œë“œ
    with open(json_path, 'r', encoding='utf-8') as f:
        json_data = json.load(f)
    print("ğŸ“„ summaries.json ë¡œë“œ ì™„ë£Œ")

    # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    grouped_data = defaultdict(lambda: {"input": None, "risk_code": None, "prompt_type": None, "avg_score": None, "scores": []})

    # ë°ì´í„° ë¶„ë¥˜
    for item in json_data:
        id_ = item["id"]
        input_ = item["input"]
        epoch = item["epoch"]
        model_score = item.get("scores", {}).get("model_graded_qa", {})

        match = re.search(r"(r\d{2})_.*?(p[^_]+)", id_)
        if not match:
            continue
        risk_code, prompt_code = match.groups()

        grouped_data[id_]["input"] = input_
        grouped_data[id_]["risk_code"] = risk_code # ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬ ëª…ì„ í‘œì‹œí•˜ë ¤ë©´ ë§¤í•‘ ì‘ì—… ì¶”ê°€ì ìœ¼ë¡œ í•„ìš”
        grouped_data[id_]["prompt_type"] = prompt_types[prompt_code]
        grouped_data[id_]["scores"].append({
            "epoch": epoch,
            "model_graded_qa": model_score
        })

    # ì •ë ¬: epoch ì˜¤ë¦„ì°¨ìˆœ
    for entry in grouped_data.values():
        entry["scores"].sort(key=lambda x: x["epoch"])


    # dictì˜ key ê°’ì„ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë¦¬. ì§€ê¸ˆ í•„ìš”ëŠ” ì—†ì§€ë§Œ, keys()ë¥¼ ì‚¬ìš©í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ì„œ ì¼ë‹¨ ì •ë ¬
    sorted_grouped_data = OrderedDict(
        sorted(grouped_data.items(), key=lambda x: x[0])  # x[0]ì€ id
    )

    # epoch ë³„ ìŠ¤ì½”ì–´ì˜ í‰ê·  ì ìˆ˜(avg_score) ê³„ì‚°
    for key in sorted_grouped_data.keys():
        score_sum=0.0

        if isinstance(sorted_grouped_data[key]['scores'], list):
            for i in range(len(sorted_grouped_data[key]["scores"])):
                if sorted_grouped_data[key]["scores"][i]["model_graded_qa"]["value"] in ["1", "2", "3", "4", "5"]:
                    score_sum += float(sorted_grouped_data[key]["scores"][i]["model_graded_qa"]["value"])
                else:
                    print(f'[GRADE ì˜¤ë¥˜ ë°œìƒ] data id: {key}')
            avg_score = ( score_sum / len(sorted_grouped_data[key]["scores"]) )
            sorted_grouped_data[key]["avg_score"] = avg_score
        else:
            sorted_grouped_data[key]["avg_score"] = sorted_grouped_data[key]["scores"]["model_graded_qa"]["value"]


    # # í„°ë¯¸ë„ì— ê²°ê³¼ ì¶œë ¥ (ìš”ì•½)
    # for id_, data in sorted_grouped_data.items():
    #     print(f"\nID: {id_}")
    #     print(f"Input: {data['input']}")
    #     print(f"avg_score: {data['avg_score']}")
    #     for score in data["scores"]:
    #         print(f"  Epoch {score['epoch']}: value={score['model_graded_qa'].get('value')}")

    return sorted_grouped_data

    #------------------------------------------------------------------------------------------------------------------------------

    # âœ… ì œì™¸ëœ risk í–‰ì— íšŒìƒ‰ ìŠ¤íƒ€ì¼ ì ìš©

def highlight_excluded_rows_factory(excluded_ids):
    excluded_prefixes = tuple(f"{i}." for i in sorted(excluded_ids))

    def highlight_excluded_rows(row):
        if any(str(row.name).startswith(prefix) for prefix in excluded_prefixes):
            return ['background-color: #f5f5f5; color: #bbbbbb'] * len(row)
        return [''] * len(row)

    return highlight_excluded_rows